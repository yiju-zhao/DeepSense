{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_arxiv_dummy_data():\n",
    "    try:\n",
    "        delay = random.randint(1, 3)  # 随机延迟 1 到 10 秒\n",
    "        time.sleep(delay)  # 模拟网络延迟\n",
    "        # Get the path to the local file\n",
    "        file_path = os.path.join(os.getcwd(), \"arxiv_dummy_data.xml\")\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            logger.error(f\"File not found: {file_path}\")\n",
    "            raise FileNotFoundError(f\"Could not find arxiv_dummy_data.xml at {file_path}\")\n",
    "        # Read and validate file content\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            response = file.read()\n",
    "            \n",
    "        if not response:\n",
    "            logger.error(\"File is empty\")\n",
    "            raise ValueError(\"arxiv_dummy_data.xml is empty\")\n",
    "            \n",
    "        logger.info(f\"Successfully read {len(response)} bytes from file\")\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error simulating network delay: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully read 131386 bytes from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy data retrieved successfully.\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "    <link href=\"ht\n"
     ]
    }
   ],
   "source": [
    "dummy_data = get_arxiv_dummy_data()\n",
    "if dummy_data:\n",
    "    print(\"Dummy data retrieved successfully.\")\n",
    "    print(dummy_data[:100])  # Print the first 100 characters of the dummy data\n",
    "else:\n",
    "    print(\"Failed to retrieve dummy data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'feedparser' has no attribute '_FeedParserMixin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfeedparser\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfeedparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_FeedParserMixin\u001b[49m.namespaces[\u001b[33m'\u001b[39m\u001b[33mhttp://a9.com/-/spec/opensearch/1.1/\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mopensearch\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m feedparser._FeedParserMixin.namespaces[\u001b[33m'\u001b[39m\u001b[33mhttp://arxiv.org/schemas/atom\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33marxiv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m feed = feedparser.parse(dummy_data)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'feedparser' has no attribute '_FeedParserMixin'"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "feed = feedparser.parse(dummy_data)\n",
    "logger.info(f'Feed title: %s' % feed.feed.title)\n",
    "# Create a dictionary to store feed metadata\n",
    "result = {\n",
    "    'feed_metadata': {\n",
    "        'title': feed.feed.title,\n",
    "        'updated': feed.feed.updated,\n",
    "        'total_results': feed.feed.opensearch_totalresults,\n",
    "        'items_per_page': feed.feed.opensearch_itemsperpage,\n",
    "        'start_index': feed.feed.opensearch_startindex\n",
    "    },\n",
    "    'papers': []\n",
    "}\n",
    "\n",
    "# Process each entry\n",
    "for entry in feed.entries:\n",
    "    paper = {\n",
    "        'arxiv_id': entry.id,\n",
    "        'title': entry.title,\n",
    "        'authors': [author.name for author in entry.authors],\n",
    "        'affiliation': [author.get('arxiv:affiliation', '') for author in entry.authors]\n",
    "    }\n",
    "    result['papers'].append(paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'http://arxiv.org/abs/1805.02867v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.02867v2', 'updated': '2018-07-28T06:51:27Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=28, tm_hour=6, tm_min=51, tm_sec=27, tm_wday=5, tm_yday=209, tm_isdst=0), 'published': '2018-05-08T07:34:17Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=8, tm_hour=7, tm_min=34, tm_sec=17, tm_wday=1, tm_yday=128, tm_isdst=0), 'title': 'Online normalizer calculation for softmax', 'title_detail': {'type': 'text/plain', 'language': None, 'base': '', 'value': 'Online normalizer calculation for softmax'}, 'summary': 'The Softmax function is ubiquitous in machine learning, multiple previous\\nworks suggested faster alternatives for it. In this paper we propose a way to\\ncompute classical Softmax with fewer memory accesses and hypothesize that this\\nreduction in memory accesses should improve Softmax performance on actual\\nhardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to\\n1.3x and Softmax+TopK combined and fused by up to 5x.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': '', 'value': 'The Softmax function is ubiquitous in machine learning, multiple previous\\nworks suggested faster alternatives for it. In this paper we propose a way to\\ncompute classical Softmax with fewer memory accesses and hypothesize that this\\nreduction in memory accesses should improve Softmax performance on actual\\nhardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to\\n1.3x and Softmax+TopK combined and fused by up to 5x.'}, 'authors': [{'name': 'Maxim Milakov'}, {'name': 'Natalia Gimelshein'}], 'author_detail': {'name': 'Natalia Gimelshein'}, 'arxiv_affiliation': 'NVIDIA', 'author': 'Natalia Gimelshein', 'arxiv_comment': '1) Added link to the benchmark code, 2) Benchmarked Safe Softmax +\\n  Top-K fused and attributed part of 5x explicitly to fusion in sections 5.2\\n  and 6, 3) Stylistic changes, 4) Minor clarifications', 'links': [{'href': 'http://arxiv.org/abs/1805.02867v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.02867v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.PF', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.PF', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}\n",
      "Title: Online normalizer calculation for softmax\n",
      "Authors: ['Maxim Milakov', 'Natalia Gimelshein']\n",
      "authors [{'name': 'Maxim Milakov'}, {'name': 'Natalia Gimelshein'}]\n",
      "{'name': 'Natalia Gimelshein'}\n",
      "NVIDIA\n"
     ]
    }
   ],
   "source": [
    "test_entry = feed.entries[1]\n",
    "print(test_entry)\n",
    "print (f\"Title: {test_entry.title}\")\n",
    "print (f\"Authors: {[author.name for author in test_entry.authors]}\")\n",
    "print(f\"authors {test_entry.authors}\")\n",
    "print(test_entry.author_detail)\n",
    "print(test_entry.arxiv_affiliation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed Title: ArXiv Query: search_query=au:NVIDIA&id_list=&start=0&max_results=100\n",
      "Updated: 2025-03-28T00:00:00-04:00\n",
      "Total Results: 32\n",
      "Paper ID: http://arxiv.org/abs/1504.01441v3\n",
      "Title: Locally Non-rigid Registration for Mobile HDR Photography\n",
      "Published: 2015-04-07T00:29:54Z\n",
      "Summary: Image registration for stack-based HDR photography is challenging. If not\n",
      "properly accounted for, camera motion and scene changes result in artifacts in\n",
      "the composite image. Unfortunately, existing methods to address this problem\n",
      "are either accurate, but too slow for mobile devices, or fast, but prone to\n",
      "failing. We propose a method that fills this void: our approach is extremely\n",
      "fast---under 700ms on a commercial tablet for a pair of 5MP images---and\n",
      "prevents the artifacts that arise from insufficient registration quality.\n",
      "Authors: ['Orazio Gallo', 'Alejandro Troccoli', 'Jun Hu', 'Kari Pulli', 'Jan Kautz']\n",
      "Affiliations: ['NVIDIA', 'NVIDIA', 'NVIDIA', 'Duke University', 'NVIDIA', 'Light', 'NVIDIA']\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_data = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
    "    <link href=\"http://arxiv.org/api/query?search_query%3Dau%3ANVIDIA%26id_list%3D%26start%3D0%26max_results%3D100\" rel=\"self\" type=\"application/atom+xml\"/>\n",
    "    <title type=\"html\">ArXiv Query: search_query=au:NVIDIA&amp;id_list=&amp;start=0&amp;max_results=100</title>\n",
    "    <id>http://arxiv.org/api/FDHFT2fjT+rKbUJuyXDF3N1b4Zk</id>\n",
    "    <updated>2025-03-28T00:00:00-04:00</updated>\n",
    "    <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">32</opensearch:totalResults>\n",
    "    <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
    "    <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">100</opensearch:itemsPerPage>\n",
    "    <entry>\n",
    "        <id>http://arxiv.org/abs/1504.01441v3</id>\n",
    "        <updated>2015-05-05T00:15:00Z</updated>\n",
    "        <published>2015-04-07T00:29:54Z</published>\n",
    "        <title>Locally Non-rigid Registration for Mobile HDR Photography</title>\n",
    "        <summary>  Image registration for stack-based HDR photography is challenging. If not\n",
    "properly accounted for, camera motion and scene changes result in artifacts in\n",
    "the composite image. Unfortunately, existing methods to address this problem\n",
    "are either accurate, but too slow for mobile devices, or fast, but prone to\n",
    "failing. We propose a method that fills this void: our approach is extremely\n",
    "fast---under 700ms on a commercial tablet for a pair of 5MP images---and\n",
    "prevents the artifacts that arise from insufficient registration quality.\n",
    "</summary>\n",
    "        <author>\n",
    "            <name>Orazio Gallo</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Alejandro Troccoli</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Jun Hu</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Duke University</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Kari Pulli</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Light</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Jan Kautz</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <link href=\"http://arxiv.org/abs/1504.01441v3\" rel=\"alternate\" type=\"text/html\"/>\n",
    "        <link title=\"pdf\" href=\"http://arxiv.org/pdf/1504.01441v3\" rel=\"related\" type=\"application/pdf\"/>\n",
    "        <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
    "        <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
    "    </entry>\n",
    "</feed>\n",
    "\"\"\"\n",
    "\n",
    "# 定义命名空间映射：注意默认的 Atom 命名空间可以起一个别名，例如 \"atom\"\n",
    "ns = {\n",
    "    \"atom\": \"http://www.w3.org/2005/Atom\",\n",
    "    \"opensearch\": \"http://a9.com/-/spec/opensearch/1.1/\",\n",
    "    \"arxiv\": \"http://arxiv.org/schemas/atom\"\n",
    "}\n",
    "\n",
    "# 解析 XML\n",
    "root = ET.fromstring(xml_data)\n",
    "\n",
    "# 获取 feed 信息\n",
    "feed_title = root.find(\"atom:title\", ns).text\n",
    "updated = root.find(\"atom:updated\", ns).text\n",
    "total_results = root.find(\"opensearch:totalResults\", ns).text\n",
    "\n",
    "print(\"Feed Title:\", feed_title)\n",
    "print(\"Updated:\", updated)\n",
    "print(\"Total Results:\", total_results)\n",
    "\n",
    "# 遍历所有 entry 元素\n",
    "for entry in root.findall(\"atom:entry\", ns):\n",
    "    paper_id = entry.find(\"atom:id\", ns).text\n",
    "    title = entry.find(\"atom:title\", ns).text\n",
    "    published = entry.find(\"atom:published\", ns).text\n",
    "    summary = entry.find(\"atom:summary\", ns).text\n",
    "\n",
    "    # 提取所有 author 信息\n",
    "    authors = []\n",
    "    affiliations = []  # 收集所有 affiliation 数据，注意有的 author 可能有多个\n",
    "    for author in entry.findall(\"atom:author\", ns):\n",
    "        name = author.find(\"atom:name\", ns).text\n",
    "        authors.append(name)\n",
    "        # 注意 feedparser 可能会将 arxiv:affiliation 元素转换为 “arxiv_affiliation”\n",
    "        # 但使用 ElementTree 时需使用命名空间查询\n",
    "        for aff in author.findall(\"arxiv:affiliation\", ns):\n",
    "            affiliations.append(aff.text)\n",
    "\n",
    "    print(\"Paper ID:\", paper_id)\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Published:\", published)\n",
    "    print(\"Summary:\", summary.strip())\n",
    "    print(\"Authors:\", authors)\n",
    "    print(\"Affiliations:\", affiliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=&id_list=2405.14900v1&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 1 of 1 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fair Evaluation of Federated Learning Algorithms for Automated Breast Density Classification: The Results of the 2022 ACR-NCI-NVIDIA Federated Learning Challenge']\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query=\"\",\n",
    "    id_list=[\"2405.14900v1\"],\n",
    "    max_results=10,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "results = client.results(search)\n",
    "print([r.title for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=id%3A2405.14900v1&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got empty first page; stopping generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_results = client.results(search)\n",
    "print([r.title for r in all_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=&id_list=2405.14900v1&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 1 of 1 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n",
      "<class 'arxiv.Result.Author'>\n",
      "[arxiv.Result.Author('Kendall Schmidt'), arxiv.Result.Author('Benjamin Bearce'), arxiv.Result.Author('Ken Chang'), arxiv.Result.Author('Laura Coombs'), arxiv.Result.Author('Keyvan Farahani'), arxiv.Result.Author('Marawan Elbatele'), arxiv.Result.Author('Kaouther Mouhebe'), arxiv.Result.Author('Robert Marti'), arxiv.Result.Author('Ruipeng Zhang'), arxiv.Result.Author('Yao Zhang'), arxiv.Result.Author('Yanfeng Wang'), arxiv.Result.Author('Yaojun Hu'), arxiv.Result.Author('Haochao Ying'), arxiv.Result.Author('Yuyang Xu'), arxiv.Result.Author('Conrad Testagrose'), arxiv.Result.Author('Mutlu Demirer'), arxiv.Result.Author('Vikash Gupta'), arxiv.Result.Author('Ünal Akünal'), arxiv.Result.Author('Markus Bujotzek'), arxiv.Result.Author('Klaus H. Maier-Hein'), arxiv.Result.Author('Yi Qin'), arxiv.Result.Author('Xiaomeng Li'), arxiv.Result.Author('Jayashree Kalpathy-Cramer'), arxiv.Result.Author('Holger R. Roth')]\n",
      "Fair Evaluation of Federated Learning Algorithms for Automated Breast Density Classification: The Results of the 2022 ACR-NCI-NVIDIA Federated Learning Challenge\n",
      "The correct interpretation of breast density is important in the assessment\n",
      "of breast cancer risk. AI has been shown capable of accurately predicting\n",
      "breast density, however, due to the differences in imaging characteristics\n",
      "across mammography systems, models built using data from one system do not\n",
      "generalize well to other systems. Though federated learning (FL) has emerged as\n",
      "a way to improve the generalizability of AI without the need to share data, the\n",
      "best way to preserve features from all training data during FL is an active\n",
      "area of research. To explore FL methodology, the breast density classification\n",
      "FL challenge was hosted in partnership with the American College of Radiology,\n",
      "Harvard Medical School's Mass General Brigham, University of Colorado, NVIDIA,\n",
      "and the National Institutes of Health National Cancer Institute. Challenge\n",
      "participants were able to submit docker containers capable of implementing FL\n",
      "on three simulated medical facilities, each containing a unique large\n",
      "mammography dataset. The breast density FL challenge ran from June 15 to\n",
      "September 5, 2022, attracting seven finalists from around the world. The\n",
      "winning FL submission reached a linear kappa score of 0.653 on the challenge\n",
      "test data and 0.413 on an external testing dataset, scoring comparably to a\n",
      "model trained on the same data in a central location.\n",
      "2024-05-22 19:54:09+00:00\n",
      "2024-05-22 19:54:09+00:00\n",
      "http://arxiv.org/abs/2405.14900v1\n",
      "eess.IV\n",
      "['eess.IV', 'cs.CV', 'cs.LG']\n",
      "http://arxiv.org/pdf/2405.14900v1\n",
      "[arxiv.Result.Link('http://dx.doi.org/10.1016/j.media.2024.103206.', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2405.14900v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.14900v1', title='pdf', rel='related', content_type=None)]\n"
     ]
    }
   ],
   "source": [
    "for result in client.results(search):\n",
    "    print(dir(result))\n",
    "    print(result.Author)\n",
    "    print(result.authors)\n",
    "    print(result.title)\n",
    "    print(result.summary)\n",
    "    print(result.published)\n",
    "    print(result.updated)\n",
    "    print(result.entry_id)\n",
    "    print(result.primary_category)\n",
    "    print(result.categories)\n",
    "    print(result.pdf_url)\n",
    "    print(result.links)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=au%3ANVIDIA&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 32 of 32 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA\n",
      ":\n",
      "Alisson Azzolini\n",
      "Hannah Brandon\n",
      "Prithvijit Chattopadhyay\n",
      "Huayu Chen\n",
      "Jinju Chu\n",
      "Yin Cui\n",
      "Jenna Diamond\n",
      "Yifan Ding\n",
      "Francesco Ferroni\n",
      "Rama Govindaraju\n",
      "Jinwei Gu\n",
      "Siddharth Gururani\n",
      "Imad El Hanafi\n",
      "Zekun Hao\n",
      "Jacob Huffman\n",
      "Jingyi Jin\n",
      "Brendan Johnson\n",
      "Rizwan Khan\n",
      "George Kurian\n",
      "Elena Lantz\n",
      "Nayeon Lee\n",
      "Zhaoshuo Li\n",
      "Xuan Li\n",
      "Tsung-Yi Lin\n",
      "Yen-Chen Lin\n",
      "Ming-Yu Liu\n",
      "Andrew Mathau\n",
      "Yun Ni\n",
      "Lindsey Pavao\n",
      "Wei Ping\n",
      "David W. Romero\n",
      "Misha Smelyanskiy\n",
      "Shuran Song\n",
      "Lyne Tchapmi\n",
      "Andrew Z. Wang\n",
      "Boxin Wang\n",
      "Haoxiang Wang\n",
      "Fangyin Wei\n",
      "Jiashu Xu\n",
      "Yao Xu\n",
      "Xiaodong Yang\n",
      "Zhuolin Yang\n",
      "Xiaohui Zeng\n",
      "Zhe Zhang\n",
      "NVIDIA\n",
      ":\n",
      "Johan Bjorck\n",
      "Fernando Castañeda\n",
      "Nikita Cherniadev\n",
      "Xingye Da\n",
      "Runyu Ding\n",
      "Linxi \"Jim\" Fan\n",
      "Yu Fang\n",
      "Dieter Fox\n",
      "Fengyuan Hu\n",
      "Spencer Huang\n",
      "Joel Jang\n",
      "Zhenyu Jiang\n",
      "Jan Kautz\n",
      "Kaushil Kundalia\n",
      "Lawrence Lao\n",
      "Zhiqi Li\n",
      "Zongyu Lin\n",
      "Kevin Lin\n",
      "Guilin Liu\n",
      "Edith Llontop\n",
      "Loic Magne\n",
      "Ajay Mandlekar\n",
      "Avnish Narayan\n",
      "Soroush Nasiriany\n",
      "Scott Reed\n",
      "You Liang Tan\n",
      "Guanzhi Wang\n",
      "Zu Wang\n",
      "Jing Wang\n",
      "Qi Wang\n",
      "Jiannan Xiang\n",
      "Yuqi Xie\n",
      "Yinzhen Xu\n",
      "Zhenjia Xu\n",
      "Seonghyeon Ye\n",
      "Zhiding Yu\n",
      "Ao Zhang\n",
      "Hao Zhang\n",
      "Yizhou Zhao\n",
      "Ruijie Zheng\n",
      "Yuke Zhu\n",
      "NVIDIA\n",
      ":\n",
      "Hassan Abu Alhaija\n",
      "Jose Alvarez\n",
      "Maciej Bala\n",
      "Tiffany Cai\n",
      "Tianshi Cao\n",
      "Liz Cha\n",
      "Joshua Chen\n",
      "Mike Chen\n",
      "Francesco Ferroni\n",
      "Sanja Fidler\n",
      "Dieter Fox\n",
      "Yunhao Ge\n",
      "Jinwei Gu\n",
      "Ali Hassani\n",
      "Michael Isaev\n",
      "Pooya Jannaty\n",
      "Shiyi Lan\n",
      "Tobias Lasser\n",
      "Huan Ling\n",
      "Ming-Yu Liu\n",
      "Xian Liu\n",
      "Yifan Lu\n",
      "Alice Luo\n",
      "Qianli Ma\n",
      "Hanzi Mao\n",
      "Fabio Ramos\n",
      "Xuanchi Ren\n",
      "Tianchang Shen\n",
      "Shitao Tang\n",
      "Ting-Chun Wang\n",
      "Jay Wu\n",
      "Jiashu Xu\n",
      "Stella Xu\n",
      "Kevin Xie\n",
      "Yuchong Ye\n",
      "Xiaodong Yang\n",
      "Xiaohui Zeng\n",
      "Yu Zeng\n",
      "Pavel Plotnitskii\n",
      "Oleg Ovcharenko\n",
      "Vladimir Kazei\n",
      "Daniel Peter\n",
      "Tariq Alkhalifah\n",
      "NVIDIA\n",
      ":\n",
      "Niket Agarwal\n",
      "Arslan Ali\n",
      "Maciej Bala\n",
      "Yogesh Balaji\n",
      "Erik Barker\n",
      "Tiffany Cai\n",
      "Prithvijit Chattopadhyay\n",
      "Yongxin Chen\n",
      "Yin Cui\n",
      "Yifan Ding\n",
      "Daniel Dworakowski\n",
      "Jiaojiao Fan\n",
      "Michele Fenzi\n",
      "Francesco Ferroni\n",
      "Sanja Fidler\n",
      "Dieter Fox\n",
      "Songwei Ge\n",
      "Yunhao Ge\n",
      "Jinwei Gu\n",
      "Siddharth Gururani\n",
      "Ethan He\n",
      "Jiahui Huang\n",
      "Jacob Huffman\n",
      "Pooya Jannaty\n",
      "Jingyi Jin\n",
      "Seung Wook Kim\n",
      "Gergely Klár\n",
      "Grace Lam\n",
      "Shiyi Lan\n",
      "Laura Leal-Taixe\n",
      "Anqi Li\n",
      "Zhaoshuo Li\n",
      "Chen-Hsuan Lin\n",
      "Tsung-Yi Lin\n",
      "Huan Ling\n",
      "Ming-Yu Liu\n",
      "Xian Liu\n",
      "Alice Luo\n",
      "Qianli Ma\n",
      "Hanzi Mao\n",
      "Kaichun Mo\n",
      "Arsalan Mousavian\n",
      "Seungjun Nah\n",
      "Sriharsha Niverty\n",
      "David Page\n",
      "Despoina Paschalidou\n",
      "Zeeshan Patel\n",
      "Lindsey Pavao\n",
      "Morteza Ramezanali\n",
      "Fitsum Reda\n",
      "Xiaowei Ren\n",
      "Vasanth Rao Naik Sabavat\n",
      "Ed Schmerling\n",
      "Stella Shi\n",
      "Bartosz Stefaniak\n",
      "Shitao Tang\n",
      "Lyne Tchapmi\n",
      "Przemek Tredak\n",
      "Wei-Cheng Tseng\n",
      "Jibin Varghese\n",
      "Hao Wang\n",
      "Haoxiang Wang\n",
      "Heng Wang\n",
      "Ting-Chun Wang\n",
      "Fangyin Wei\n",
      "Xinyue Wei\n",
      "Jay Zhangjie Wu\n",
      "Jiashu Xu\n",
      "Wei Yang\n",
      "Lin Yen-Chen\n",
      "Xiaohui Zeng\n",
      "Yu Zeng\n",
      "Jing Zhang\n",
      "Qinsheng Zhang\n",
      "Yuxuan Zhang\n",
      "Qingqing Zhao\n",
      "Artur Zolkowski\n"
     ]
    }
   ],
   "source": [
    "for result in client.results(search):\n",
    "    for author in result.authors:\n",
    "        print(author.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([r.title for r in all_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'feedparser' has no attribute '_FeedParserMixin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfeedparser\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfeedparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_FeedParserMixin\u001b[49m.namespaces[\u001b[33m'\u001b[39m\u001b[33mhttp://a9.com/-/spec/opensearch/1.1/\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mopensearch\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m      4\u001b[39m feedparser._FeedParserMixin.namespaces[\u001b[33m'\u001b[39m\u001b[33mhttp://arxiv.org/schemas/atom\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33marxiv\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m      6\u001b[39m feed = feedparser.parse(dummy_data)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: module 'feedparser' has no attribute '_FeedParserMixin'"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "feed = feedparser.parse(dummy_data)\n",
    "logger.info(f'Feed title: %s' % feed.feed.title)\n",
    "# Create a dictionary to store feed metadata\n",
    "result = {\n",
    "    'feed_metadata': {\n",
    "        'title': feed.feed.title,\n",
    "        'updated': feed.feed.updated,\n",
    "        'total_results': feed.feed.opensearch_totalresults,\n",
    "        'items_per_page': feed.feed.opensearch_itemsperpage,\n",
    "        'start_index': feed.feed.opensearch_startindex\n",
    "    },\n",
    "    'papers': []\n",
    "}\n",
    "\n",
    "# Process each entry\n",
    "for entry in feed.entries:\n",
    "    paper = {\n",
    "        'arxiv_id': entry.id,\n",
    "        'title': entry.title,\n",
    "        'authors': [author.name for author in entry.authors],\n",
    "        'affiliation': [author.get('arxiv:affiliation', '') for author in entry.authors]\n",
    "    }\n",
    "    result['papers'].append(paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_data = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
    "    <link href=\"http://arxiv.org/api/query?search_query%3Dau%3ANVIDIA%26id_list%3D%26start%3D0%26max_results%3D100\" rel=\"self\" type=\"application/atom+xml\"/>\n",
    "    <title type=\"html\">ArXiv Query: search_query=au:NVIDIA&amp;id_list=&amp;start=0&amp;max_results=100</title>\n",
    "    <id>http://arxiv.org/api/FDHFT2fjT+rKbUJuyXDF3N1b4Zk</id>\n",
    "    <updated>2025-03-28T00:00:00-04:00</updated>\n",
    "    <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">32</opensearch:totalResults>\n",
    "    <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
    "    <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">100</opensearch:itemsPerPage>\n",
    "    <entry>\n",
    "        <id>http://arxiv.org/abs/1504.01441v3</id>\n",
    "        <updated>2015-05-05T00:15:00Z</updated>\n",
    "        <published>2015-04-07T00:29:54Z</published>\n",
    "        <title>Locally Non-rigid Registration for Mobile HDR Photography</title>\n",
    "        <summary>  Image registration for stack-based HDR photography is challenging. If not\n",
    "properly accounted for, camera motion and scene changes result in artifacts in\n",
    "the composite image. Unfortunately, existing methods to address this problem\n",
    "are either accurate, but too slow for mobile devices, or fast, but prone to\n",
    "failing. We propose a method that fills this void: our approach is extremely\n",
    "fast---under 700ms on a commercial tablet for a pair of 5MP images---and\n",
    "prevents the artifacts that arise from insufficient registration quality.\n",
    "</summary>\n",
    "        <author>\n",
    "            <name>Orazio Gallo</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Alejandro Troccoli</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Jun Hu</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Duke University</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Kari Pulli</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Light</arxiv:affiliation>\n",
    "        </author>\n",
    "        <author>\n",
    "            <name>Jan Kautz</name>\n",
    "            <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NVIDIA</arxiv:affiliation>\n",
    "        </author>\n",
    "        <link href=\"http://arxiv.org/abs/1504.01441v3\" rel=\"alternate\" type=\"text/html\"/>\n",
    "        <link title=\"pdf\" href=\"http://arxiv.org/pdf/1504.01441v3\" rel=\"related\" type=\"application/pdf\"/>\n",
    "        <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
    "        <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
    "    </entry>\n",
    "</feed>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arxiv_feed(xml_data: str) -> dict:\n",
    "    \"\"\"\n",
    "    解析 arXiv API 返回的 XML 数据，提取 feed 信息和论文条目，并返回为字典格式。\n",
    "\n",
    "    参数:\n",
    "        xml_data: str - 包含 arXiv API 响应的 XML 数据字符串。\n",
    "\n",
    "    返回:\n",
    "        dict: 包含 feed 信息和论文条目的字典，结构如下：\n",
    "            {\n",
    "                \"feed_info\": { \"feed_title\": ..., \"updated\": ..., \"total_results\": ... },\n",
    "                \"papers\": [\n",
    "                    {\n",
    "                        \"paper_id\": ...,\n",
    "                        \"title\": ...,\n",
    "                        \"published\": ...,\n",
    "                        \"summary\": ...,\n",
    "                        \"authors\": [\n",
    "                            {\"name\": ..., \"affiliations\": [...]},\n",
    "                            ...\n",
    "                        ]\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "    ns = {\n",
    "        \"atom\": \"http://www.w3.org/2005/Atom\",\n",
    "        \"opensearch\": \"http://a9.com/-/spec/opensearch/1.1/\",\n",
    "        \"arxiv\": \"http://arxiv.org/schemas/atom\"\n",
    "    }\n",
    "    root = ET.fromstring(xml_data)\n",
    "\n",
    "    feed_info = {\n",
    "        \"feed_title\": root.find(\"atom:title\", ns).text,\n",
    "        \"updated\": root.find(\"atom:updated\", ns).text,\n",
    "        \"total_results\": root.find(\"opensearch:totalResults\", ns).text,\n",
    "        \"items_per_page\": root.find(\"opensearch:itemsPerPage\", ns).text,\n",
    "        \"start_index\": root.find(\"opensearch:startIndex\", ns).text\n",
    "    }\n",
    "\n",
    "    papers = []\n",
    "    for entry in root.findall(\"atom:entry\", ns):\n",
    "        # 提取 primary_category\n",
    "        primary_category_elem = entry.find(\"arxiv:primary_category\", ns)\n",
    "        primary_category = primary_category_elem.attrib.get(\"term\") if primary_category_elem is not None else None\n",
    "\n",
    "        # 提取所有 category（默认命名空间下）\n",
    "        categories = []\n",
    "        for cat in entry.findall(\"atom:category\", ns):\n",
    "            term = cat.attrib.get(\"term\")\n",
    "            if term:\n",
    "                categories.append(term)\n",
    "    \n",
    "        paper = {\n",
    "            \"arxiv_id\": entry.find(\"atom:id\", ns).text,\n",
    "            \"title\": entry.find(\"atom:title\", ns).text,\n",
    "            \"published\": entry.find(\"atom:published\", ns).text,\n",
    "            \"summary\": entry.find(\"atom:summary\", ns).text.strip() if entry.find(\"atom:summary\", ns) is not None else \"\",\n",
    "            \"authors\": [],\n",
    "            \"primary_category\": primary_category,\n",
    "            \"categories\": categories\n",
    "        }\n",
    "        for author in entry.findall(\"atom:author\", ns):\n",
    "            name = author.find(\"atom:name\", ns).text\n",
    "            aff_list = [aff.text for aff in author.findall(\"arxiv:affiliation\", ns)]\n",
    "            paper[\"authors\"].append({\"name\": name, \"affiliations\": aff_list})\n",
    "        papers.append(paper)\n",
    "\n",
    "    return {\n",
    "        \"feed_info\": feed_info,\n",
    "        \"papers\": papers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feed_info': {'feed_title': 'ArXiv Query: search_query=au:NVIDIA&id_list=&start=0&max_results=100', 'updated': '2025-03-28T00:00:00-04:00', 'total_results': '32', 'items_per_page': '100', 'start_index': '0'}, 'papers': [{'arxiv_id': 'http://arxiv.org/abs/1504.01441v3', 'title': 'Locally Non-rigid Registration for Mobile HDR Photography', 'published': '2015-04-07T00:29:54Z', 'summary': 'Image registration for stack-based HDR photography is challenging. If not\\nproperly accounted for, camera motion and scene changes result in artifacts in\\nthe composite image. Unfortunately, existing methods to address this problem\\nare either accurate, but too slow for mobile devices, or fast, but prone to\\nfailing. We propose a method that fills this void: our approach is extremely\\nfast---under 700ms on a commercial tablet for a pair of 5MP images---and\\nprevents the artifacts that arise from insufficient registration quality.', 'authors': [{'name': 'Orazio Gallo', 'affiliations': ['NVIDIA']}, {'name': 'Alejandro Troccoli', 'affiliations': ['NVIDIA']}, {'name': 'Jun Hu', 'affiliations': ['NVIDIA', 'Duke University']}, {'name': 'Kari Pulli', 'affiliations': ['NVIDIA', 'Light']}, {'name': 'Jan Kautz', 'affiliations': ['NVIDIA']}], 'primary_category': 'cs.CV', 'categories': ['cs.CV']}]}\n"
     ]
    }
   ],
   "source": [
    "print(parse_arxiv_feed(xml_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
